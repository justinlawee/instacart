# -----------------------------------------------------------------------------
# Instacart Reorder Prediction
#
# This project builds the data transformation layer for an end-to-end AI-powered
# reorder prediction pipeline using Snowflake. It includes:
# - Raw Instacart data ingestion and staging
# - Feature engineering and aggregation using dbt
# - ML-ready outputs consumed by Snowpark for model training
#
# The project is part of a larger AI workflow that also includes:
# - Model training with Snowpark Python (Random Forest / XGBoost)
# - Prediction outputs stored in Snowflake
# - Optional GenAI enrichment with Cortex
# - Visualization in Snowsight
# -----------------------------------------------------------------------------

# Name of the project
name: 'instacart'

# Versioning for the project (can match your repo release versioning)
version: '1.0.0'

# dbt config version (2 is standard for dbt 1.x+)
config-version: 2

# Profile name used in profiles.yml for Snowflake connection
profile: 'default'

# Directories where dbt looks for different types of resources
model-paths: ["models"]       # Your main model files (SQL logic)
analysis-paths: ["analyses"]  # Optional: for ad hoc SQL analyses
test-paths: ["tests"]         # Custom data quality tests
seed-paths: ["seeds"]         # Optional: CSVs loaded via dbt seed
macro-paths: ["macros"]       # Optional: Jinja macros for reusable logic
snapshot-paths: ["snapshots"] # Optional: historical snapshots (SCD tracking)

# Where dbt stores compiled SQL and artifacts
target-path: "target"
clean-targets:
  - "target"
  - "dbt_packages"

# Default model configs (can be overridden in each model)
models:
  instacart:
    +materialized: table  # Build models as tables by default
